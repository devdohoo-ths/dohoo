import { OpenAI } from 'openai';
import { supabase } from '../lib/supabaseClient.js';
import { gerarAudioElevenLabs } from './elevenLabs.js';
import fs from 'fs';
import path from 'path';
import { execSync } from 'child_process';
import { fileURLToPath } from 'url';
import { loadAISettings, validateAIEnabled, validateAudioEnabled, validateTranscriptionEnabled, validateSynthesisEnabled, getAIProcessingConfig } from './ai/aiSettingsMiddleware.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

class AudioProcessor {
    constructor() {
        this.openai = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        });
    }

    async processAudio(audioBuffer, chatId, companyId) {
        try {
            console.log('üéµ Iniciando processamento de √°udio...');
            console.log('üìù Par√¢metros:', { chatId, companyId, bufferSize: audioBuffer.length });

            // 1. Carregar configura√ß√µes de IA da organiza√ß√£o
            console.log('üîß Carregando configura√ß√µes de IA para organiza√ß√£o:', companyId);
            const aiSettings = await loadAISettings(companyId);
            
            // Validar se a IA est√° habilitada
            validateAIEnabled(aiSettings);
            
            // Validar se o processamento de √°udio est√° habilitado
            validateAudioEnabled(aiSettings);
            
            // Obter configura√ß√µes formatadas para processamento
            const processingConfig = getAIProcessingConfig(aiSettings);
            
            console.log('‚öôÔ∏è Configura√ß√µes de √°udio carregadas:', {
                audioEnabled: processingConfig.audio.enabled,
                transcriptionEnabled: processingConfig.audio.transcriptionEnabled,
                synthesisEnabled: processingConfig.audio.synthesisEnabled,
                provider: processingConfig.audio.provider
            });

            // 2. Salvar √°udio do WhatsApp
            const audioPath = await this.saveWhatsAppAudio(audioBuffer, chatId);
            console.log('‚úÖ √Åudio do WhatsApp salvo em:', audioPath);

            // 3. Transcrever √°udio usando OpenAI (se habilitado)
            let transcript = null;
            if (processingConfig.audio.transcriptionEnabled) {
                console.log('üé§ Iniciando transcri√ß√£o...');
                transcript = await this.transcribeAudio(audioPath);
                console.log('‚úÖ Transcri√ß√£o conclu√≠da:', transcript);
            } else {
                console.log('‚ùå Transcri√ß√£o desabilitada - pulando etapa');
                transcript = "[Transcri√ß√£o desabilitada]";
            }

            // 4. Processar com IA
            console.log('ü§ñ Processando com IA...');
            const aiResponse = await this.processWithAI(transcript, companyId, processingConfig);
            console.log('‚úÖ Resposta da IA:', aiResponse);

            // 5. Converter resposta para √°udio (se habilitado)
            let audioResponse = null;
            if (processingConfig.audio.synthesisEnabled && processingConfig.audio.provider === 'elevenlabs') {
                console.log('üîä Convertendo resposta para √°udio...');
                audioResponse = await this.convertToAudio(aiResponse, companyId, processingConfig.audio.voiceId);
                console.log('‚úÖ √Åudio de resposta gerado:', audioResponse);
            } else {
                console.log('‚ùå S√≠ntese de √°udio desabilitada - retornando apenas texto');
            }

            return {
                transcript,
                aiResponse,
                audioUrl: audioResponse,
                settings_used: {
                    transcriptionEnabled: processingConfig.audio.transcriptionEnabled,
                    synthesisEnabled: processingConfig.audio.synthesisEnabled,
                    provider: processingConfig.audio.provider,
                    model: processingConfig.model
                }
            };
        } catch (error) {
            console.error('‚ùå Erro no processamento de √°udio:', error);
            console.error('Stack trace:', error.stack);
            
            // Se for erro de configura√ß√£o desabilitada, retornar erro espec√≠fico
            if (error.message.includes('disabled')) {
                throw new Error(`Funcionalidade desabilitada: ${error.message}`);
            }
            
            throw error;
        }
    }

    async saveWhatsAppAudio(audioBuffer, chatId) {
        try {
            console.log('üíæ Salvando √°udio do WhatsApp...');
            const uploadDir = path.join(process.cwd(), 'uploads', 'whatsapp', chatId);
            console.log('üìÅ Diret√≥rio de upload:', uploadDir);
            
            fs.mkdirSync(uploadDir, { recursive: true });
            console.log('‚úÖ Diret√≥rio criado/verificado');

            const fileName = `${Date.now()}_whatsapp_audio.ogg`;
            const filePath = path.join(uploadDir, fileName);
            
            fs.writeFileSync(filePath, audioBuffer);
            console.log('‚úÖ Arquivo salvo:', filePath);
            
            return filePath;
        } catch (error) {
            console.error('‚ùå Erro ao salvar √°udio:', error);
            throw error;
        }
    }

    async transcribeAudio(audioPath) {
        try {
            console.log('üé§ Iniciando transcri√ß√£o do √°udio:', audioPath);
            
            // Verificar se o arquivo existe
            if (!fs.existsSync(audioPath)) {
                throw new Error(`Arquivo de √°udio n√£o encontrado: ${audioPath}`);
            }

            // Converter para MP3 se necess√°rio (WhatsApp envia em OGG)
            const mp3Path = audioPath.replace('.ogg', '.mp3');
            console.log('üîÑ Convertendo para MP3:', mp3Path);
            
            try {
                execSync(`ffmpeg -i "${audioPath}" "${mp3Path}"`);
                console.log('‚úÖ Convers√£o para MP3 conclu√≠da');
            } catch (error) {
                console.error('‚ùå Erro na convers√£o para MP3:', error);
                throw new Error('Falha ao converter √°udio para MP3');
            }

            console.log('üéµ Enviando para transcri√ß√£o OpenAI...');
            const audioFile = fs.createReadStream(mp3Path);
            const response = await this.openai.audio.transcriptions.create({
                file: audioFile,
                model: "whisper-1",
                language: "pt"
            });
            console.log('‚úÖ Transcri√ß√£o recebida da OpenAI');

            // Limpar arquivos tempor√°rios
            try {
                fs.unlinkSync(mp3Path);
                fs.unlinkSync(audioPath);
                console.log('üßπ Arquivos tempor√°rios removidos');
            } catch (error) {
                console.warn('‚ö†Ô∏è Erro ao remover arquivos tempor√°rios:', error);
            }

            return response.text;
        } catch (error) {
            console.error('‚ùå Erro na transcri√ß√£o:', error);
            throw error;
        }
    }

    async processWithAI(text, companyId, processingConfig) {
        try {
            // Usar configura√ß√µes carregadas em vez de buscar novamente
            const completion = await this.openai.chat.completions.create({
                model: processingConfig.model,
                messages: [
                    {
                        role: "system",
                        content: "Voc√™ √© um assistente virtual amig√°vel e prestativo. Responda de forma clara e concisa."
                    },
                    {
                        role: "user",
                        content: text
                    }
                ],
                temperature: processingConfig.temperature,
                max_tokens: processingConfig.maxTokens
            });

            return completion.choices[0].message.content;
        } catch (error) {
            console.error('‚ùå Erro no processamento com IA:', error);
            throw error;
        }
    }

    async convertToAudio(text, companyId, voiceId) {
        try {
            // Usar Eleven Labs ou Google TTS baseado nas configura√ß√µes
            const { data: settings } = await supabase
                .from('ai_settings')
                .select('settings')
                .eq('organization_id', companyId)
                .single();

            if (!settings?.settings?.audio?.enabled) {
                throw new Error('Audio processing not enabled');
            }

            if (settings.settings.audio.provider === 'elevenlabs') {
                return await gerarAudioElevenLabs(text, companyId, voiceId);
            } else if (settings.settings.audio.provider === 'google') {
                // Implementar convers√£o com Google TTS se necess√°rio
                throw new Error('Google TTS not implemented yet');
            } else {
                throw new Error('No audio provider configured');
            }
        } catch (error) {
            console.error('‚ùå Erro na convers√£o para √°udio:', error);
            throw error;
        }
    }
}

export default new AudioProcessor(); 