import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

async function consolidateMigrations() {
  try {
    console.log('üîÑ Consolidando migra√ß√µes SQL...\n');
    
    // Caminho para as migra√ß√µes
    const migrationsPath = path.join(__dirname, '../supabase/migrations');
    const outputPath = path.join(__dirname, '../supabase/schema-complete.sql');
    
    // Ler todos os arquivos SQL
    const files = await fs.readdir(migrationsPath);
    const sqlFiles = files
      .filter(file => file.endsWith('.sql'))
      .sort(); // Ordenar alfabeticamente (ordem cronol√≥gica)
    
    console.log(`üìã Encontrados ${sqlFiles.length} arquivos de migra√ß√£o\n`);
    
    let consolidatedSQL = `-- ============================================
-- SCHEMA COMPLETO - DOHOO BACKEND
-- ============================================
-- Este arquivo cont√©m todas as migra√ß√µes consolidadas
-- Execute este arquivo no SQL Editor do Supabase
-- Data de gera√ß√£o: ${new Date().toISOString()}
-- Total de migra√ß√µes: ${sqlFiles.length}
-- ============================================

-- Desabilitar temporariamente verifica√ß√µes que podem causar erros
SET check_function_bodies = false;

-- ============================================
-- SE√á√ÉO 1: TABELAS BASE (Devem ser criadas PRIMEIRO)
-- ============================================

-- Criar fun√ß√£o update_updated_at_column (necess√°ria para triggers)
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Criar enum para roles do sistema (necess√°rio para v√°rias tabelas)
DO $$ BEGIN
    CREATE TYPE public.user_role AS ENUM ('super_admin', 'admin', 'agent');
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

-- Criar tabela organizations (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.organizations (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  name TEXT NOT NULL,
  domain TEXT,
  logo_url TEXT,
  settings JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Criar tabela profiles (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.profiles (
  id UUID REFERENCES auth.users(id) ON DELETE CASCADE PRIMARY KEY,
  name TEXT,
  email TEXT,
  avatar_url TEXT,
  department TEXT,
  is_online BOOLEAN DEFAULT FALSE,
  organization_id UUID REFERENCES public.organizations(id),
  user_role public.user_role DEFAULT 'agent',
  permissions JSONB DEFAULT '{"chat": true, "analytics": false, "users": false, "settings": false}',
  show_name_in_chat BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Criar tabela chats (BASE - referenciada por messages)
CREATE TABLE IF NOT EXISTS public.chats (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  name TEXT NOT NULL,
  platform TEXT NOT NULL DEFAULT 'whatsapp',
  remote_jid TEXT,
  avatar_url TEXT,
  status TEXT DEFAULT 'active',
  priority TEXT DEFAULT 'medium',
  assigned_agent_id UUID REFERENCES auth.users(id),
  department TEXT,
  is_group BOOLEAN DEFAULT FALSE,
  participants JSONB DEFAULT '[]',
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Criar tabela messages (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.messages (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  chat_id UUID REFERENCES public.chats(id) ON DELETE CASCADE NOT NULL,
  sender_id UUID REFERENCES auth.users(id),
  sender_name TEXT,
  content TEXT,
  message_type TEXT DEFAULT 'text',
  media_url TEXT,
  is_from_me BOOLEAN DEFAULT FALSE,
  is_internal BOOLEAN DEFAULT FALSE,
  is_important BOOLEAN DEFAULT FALSE,
  status TEXT DEFAULT 'sent',
  message_id TEXT,
  reply_to UUID REFERENCES public.messages(id),
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Criar tabela whatsapp_accounts (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.whatsapp_accounts (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) NOT NULL,
  name TEXT NOT NULL,
  phone_number TEXT,
  status TEXT NOT NULL DEFAULT 'disconnected' CHECK (status IN ('connected', 'disconnected', 'connecting', 'error')),
  qr_code TEXT,
  session_data JSONB DEFAULT '{}',
  account_id TEXT UNIQUE NOT NULL,
  last_connected_at TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Criar tabela ai_credits (BASE - referenciada/modificada por v√°rias migra√ß√µes)
CREATE TABLE IF NOT EXISTS public.ai_credits (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id),
  organization_id UUID REFERENCES public.organizations(id),
  credits_purchased INTEGER NOT NULL DEFAULT 0,
  credits_used INTEGER NOT NULL DEFAULT 0,
  credits_remaining INTEGER GENERATED ALWAYS AS (credits_purchased - credits_used) STORED,
  last_purchase_at TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Criar tabela ai_token_usage (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.ai_token_usage (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) NOT NULL,
  organization_id UUID REFERENCES public.organizations(id),
  assistant_id UUID REFERENCES public.ai_assistants(id),
  chat_id UUID REFERENCES public.chats(id) ON DELETE CASCADE,
  tokens_used INTEGER NOT NULL,
  model_used TEXT NOT NULL,
  cost_in_credits INTEGER NOT NULL,
  message_type TEXT DEFAULT 'chat',
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Criar tabela credit_transactions (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.credit_transactions (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) NOT NULL,
  organization_id UUID REFERENCES public.organizations(id),
  transaction_type TEXT NOT NULL CHECK (transaction_type IN ('purchase', 'usage', 'refund')),
  credits_amount INTEGER NOT NULL,
  cost_usd DECIMAL(10,2),
  payment_status TEXT DEFAULT 'pending' CHECK (payment_status IN ('pending', 'completed', 'failed', 'refunded')),
  stripe_payment_id TEXT,
  description TEXT,
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Criar tabela ai_assistants (BASE - referenciada por v√°rias outras)
CREATE TABLE IF NOT EXISTS public.ai_assistants (
  id UUID NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  description TEXT,
  avatar_url TEXT,
  personality TEXT,
  instructions TEXT NOT NULL,
  model TEXT NOT NULL,
  provider TEXT NOT NULL,
  is_active BOOLEAN NOT NULL DEFAULT true,
  tags TEXT[],
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- ============================================
-- SE√á√ÉO 2: MIGRA√á√ïES EM ORDEM
-- ============================================

`;

    let fileCount = 0;
    let totalSize = 0;
    
    // Processar cada arquivo
    for (const file of sqlFiles) {
      const filePath = path.join(migrationsPath, file);
      const content = await fs.readFile(filePath, 'utf8');
      
      // Adicionar separador com nome do arquivo
      consolidatedSQL += `\n-- ============================================\n`;
      consolidatedSQL += `-- Migra√ß√£o: ${file}\n`;
      consolidatedSQL += `-- ============================================\n\n`;
      
      // Limpar conte√∫do: remover linhas vazias excessivas no in√≠cio
      let cleanedContent = content.trim();
      
      // Remover coment√°rios de timestamp se existirem
      cleanedContent = cleanedContent.replace(/^--.*\d{4}-\d{2}-\d{2}.*$/gm, '');
      
      // Remover cria√ß√µes de tabelas base que j√° foram criadas na se√ß√£o 1
      // Isso evita duplica√ß√£o e conflitos de depend√™ncias
      if (file.includes('20250614110827')) {
        // Remover cria√ß√£o de organizations e user_role (j√° criados na se√ß√£o 1)
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+(IF\s+NOT\s+EXISTS\s+)?public\.organizations[^;]*;/gis, '-- organizations j√° criada na se√ß√£o 1');
        cleanedContent = cleanedContent.replace(/CREATE\s+TYPE\s+(IF\s+NOT\s+EXISTS\s+)?public\.user_role[^;]*;/gis, '-- user_role j√° criado na se√ß√£o 1');
      }
      
      if (file.includes('20250614102324')) {
        // Remover cria√ß√£o de chats e messages (j√° criados na se√ß√£o 1)
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+IF\s+NOT\s+EXISTS\s+public\.chats[^;]*;/gis, '-- chats j√° criada na se√ß√£o 1');
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+IF\s+NOT\s+EXISTS\s+public\.messages[^;]*;/gis, '-- messages j√° criada na se√ß√£o 1');
        cleanedContent = cleanedContent.replace(/DROP\s+TABLE\s+IF\s+EXISTS\s+public\.whatsapp_messages[^;]*;/gis, '-- whatsapp_messages j√° removida na se√ß√£o 1');
      }
      
      if (file.includes('20250623000001-create-profiles-table')) {
        // Remover cria√ß√£o de profiles (j√° criada na se√ß√£o 1)
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+IF\s+NOT\s+EXISTS\s+public\.profiles[^;]*;/gis, '-- profiles j√° criada na se√ß√£o 1');
      }
      
      if (file.includes('20250614175634') || file.includes('0ffc7855-8f19-477a-b276-f46f81238fa4')) {
        // Remover cria√ß√£o de whatsapp_accounts (j√° criada na se√ß√£o 1)
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+(IF\s+NOT\s+EXISTS\s+)?public\.whatsapp_accounts[^;]*;/gis, '-- whatsapp_accounts j√° criada na se√ß√£o 1');
      }
      
      if (file.includes('20250617005038') || file.includes('2ab116a1-02b9-4162-b28e-f6dff92a8e68')) {
        // Remover cria√ß√£o de ai_credits, ai_token_usage e credit_transactions (j√° criadas na se√ß√£o 1)
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+(IF\s+NOT\s+EXISTS\s+)?public\.ai_credits[^;]*;/gis, '-- ai_credits j√° criada na se√ß√£o 1');
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+(IF\s+NOT\s+EXISTS\s+)?public\.ai_token_usage[^;]*;/gis, '-- ai_token_usage j√° criada na se√ß√£o 1');
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+(IF\s+NOT\s+EXISTS\s+)?public\.credit_transactions[^;]*;/gis, '-- credit_transactions j√° criada na se√ß√£o 1');
      }
      
      if (file.includes('20250615203659') || file.includes('887ae191-1cd9-4ad7-9f77-3fe1f11db30c')) {
        // Remover cria√ß√£o de ai_assistants (j√° criada na se√ß√£o 1)
        cleanedContent = cleanedContent.replace(/CREATE\s+TABLE\s+(IF\s+NOT\s+EXISTS\s+)?public\.ai_assistants[^;]*;/gis, '-- ai_assistants j√° criada na se√ß√£o 1');
      }
      
      // Remover fun√ß√£o update_updated_at_column se j√° foi criada (j√° est√° na se√ß√£o 1)
      cleanedContent = cleanedContent.replace(/CREATE\s+OR\s+REPLACE\s+FUNCTION\s+update_updated_at_column\(\).*?END;\s*\$\$[^;]*;/gis, '-- update_updated_at_column j√° criada na se√ß√£o 1');
      
      // Remover fun√ß√£o update_updated_at (alias) tamb√©m
      cleanedContent = cleanedContent.replace(/EXECUTE\s+FUNCTION\s+public\.update_updated_at\(\)/gis, 'EXECUTE FUNCTION public.update_updated_at_column()');
      
      // Garantir que termina com ponto-e-v√≠rgula ou nova linha
      if (!cleanedContent.endsWith(';') && !cleanedContent.endsWith('\n')) {
        cleanedContent += ';\n';
      } else if (!cleanedContent.endsWith('\n')) {
        cleanedContent += '\n';
      }
      
      consolidatedSQL += cleanedContent + '\n\n';
      
      fileCount++;
      totalSize += content.length;
      console.log(`‚úÖ Processado: ${file} (${(content.length / 1024).toFixed(2)} KB)`);
    }
    
    // Adicionar coment√°rio final
    consolidatedSQL += `\n-- ============================================\n`;
    consolidatedSQL += `-- FIM DAS MIGRA√á√ïES\n`;
    consolidatedSQL += `-- Total: ${fileCount} arquivos consolidados\n`;
    consolidatedSQL += `-- ============================================\n`;
    
    // Salvar arquivo consolidado
    await fs.writeFile(outputPath, consolidatedSQL, 'utf8');
    
    const fileSizeKB = (totalSize / 1024).toFixed(2);
    const outputSizeKB = (consolidatedSQL.length / 1024).toFixed(2);
    
    console.log('\n' + '='.repeat(50));
    console.log('‚úÖ CONSOLIDA√á√ÉO CONCLU√çDA!');
    console.log('='.repeat(50));
    console.log(`üìÅ Arquivo gerado: supabase/schema-complete.sql`);
    console.log(`üìä Total de migra√ß√µes: ${fileCount}`);
    console.log(`üì¶ Tamanho total: ${outputSizeKB} KB`);
    console.log('\nüí° PR√ìXIMOS PASSOS:');
    console.log('   1. Acesse o Supabase Dashboard');
    console.log('   2. V√° em SQL Editor');
    console.log('   3. Abra o arquivo: backend/supabase/schema-complete.sql');
    console.log('   4. Copie TODO o conte√∫do');
    console.log('   5. Cole no SQL Editor do Supabase');
    console.log('   6. Clique em "Run" (ou Ctrl+Enter)');
    console.log('\n‚ö†Ô∏è  IMPORTANTE:');
    console.log('   - O arquivo pode ser grande, aguarde a execu√ß√£o');
    console.log('   - Alguns erros de "already exists" s√£o normais');
    console.log('   - Verifique os logs para confirmar cria√ß√£o das tabelas');
    console.log('='.repeat(50) + '\n');
    
    return {
      success: true,
      file: outputPath,
      fileCount,
      size: consolidatedSQL.length
    };
    
  } catch (error) {
    console.error('‚ùå Erro ao consolidar migra√ß√µes:', error);
    throw error;
  }
}

// Executar se chamado diretamente
if (import.meta.url === `file://${process.argv[1]}` || process.argv[1]?.includes('consolidate-migrations')) {
  consolidateMigrations()
    .then(() => {
      console.log('‚úÖ Script executado com sucesso!');
      process.exit(0);
    })
    .catch((error) => {
      console.error('‚ùå Erro:', error);
      process.exit(1);
    });
}

export { consolidateMigrations };

